<!DOCTYPE html>



  


<html class="theme-next gemini use-motion" lang="">
<head>
  <meta charset="UTF-8"/>
<meta http-equiv="X-UA-Compatible" content="IE=edge" />
<meta name="viewport" content="width=device-width, initial-scale=1, maximum-scale=1"/>
<meta name="theme-color" content="#222">









<meta http-equiv="Cache-Control" content="no-transform" />
<meta http-equiv="Cache-Control" content="no-siteapp" />
















  
  
  <link href="/lib/fancybox/source/jquery.fancybox.css?v=2.1.5" rel="stylesheet" type="text/css" />







<link href="/lib/font-awesome/css/font-awesome.min.css?v=4.6.2" rel="stylesheet" type="text/css" />

<link href="/css/main.css?v=5.1.4" rel="stylesheet" type="text/css" />


  <link rel="apple-touch-icon" sizes="180x180" href="/images/apple-touch-icon-next.png?v=5.1.4">


  <link rel="icon" type="image/png" sizes="32x32" href="/images/favicon-32x32-next.png?v=5.1.4">


  <link rel="icon" type="image/png" sizes="16x16" href="/images/favicon-16x16-next.png?v=5.1.4">


  <link rel="mask-icon" href="/images/logo.svg?v=5.1.4" color="#222">





  <meta name="keywords" content="Hexo, NexT" />










<meta name="description" content="Why always me - Mario Balotelli">
<meta property="og:type" content="website">
<meta property="og:title" content="chenghaz Official 1.0">
<meta property="og:url" content="http://chenghaz.github.io/index.html">
<meta property="og:site_name" content="chenghaz Official 1.0">
<meta property="og:description" content="Why always me - Mario Balotelli">
<meta property="og:locale" content="default">
<meta name="twitter:card" content="summary">
<meta name="twitter:title" content="chenghaz Official 1.0">
<meta name="twitter:description" content="Why always me - Mario Balotelli">



<script type="text/javascript" id="hexo.configurations">
  var NexT = window.NexT || {};
  var CONFIG = {
    root: '/',
    scheme: 'Gemini',
    version: '5.1.4',
    sidebar: {"position":"left","display":"post","offset":12,"b2t":false,"scrollpercent":false,"onmobile":false},
    fancybox: true,
    tabs: true,
    motion: {"enable":true,"async":false,"transition":{"post_block":"fadeIn","post_header":"slideDownIn","post_body":"slideDownIn","coll_header":"slideLeftIn","sidebar":"slideUpIn"}},
    duoshuo: {
      userId: '0',
      author: 'Author'
    },
    algolia: {
      applicationID: '',
      apiKey: '',
      indexName: '',
      hits: {"per_page":10},
      labels: {"input_placeholder":"Search for Posts","hits_empty":"We didn't find any results for the search: ${query}","hits_stats":"${hits} results found in ${time} ms"}
    }
  };
</script>



  <link rel="canonical" href="http://chenghaz.github.io/"/>





  <title>chenghaz Official 1.0</title>
  








</head>

<body itemscope itemtype="http://schema.org/WebPage" lang="default">

  
  
    
  

  <div class="container sidebar-position-left 
  page-home">
    <div class="headband"></div>

    <header id="header" class="header" itemscope itemtype="http://schema.org/WPHeader">
      <div class="header-inner"><div class="site-brand-wrapper">
  <div class="site-meta ">
    

    <div class="custom-logo-site-title">
      <a href="/"  class="brand" rel="start">
        <span class="logo-line-before"><i></i></span>
        <span class="site-title">chenghaz Official 1.0</span>
        <span class="logo-line-after"><i></i></span>
      </a>
    </div>
      
        <p class="site-subtitle"></p>
      
  </div>

  <div class="site-nav-toggle">
    <button>
      <span class="btn-bar"></span>
      <span class="btn-bar"></span>
      <span class="btn-bar"></span>
    </button>
  </div>
</div>

<nav class="site-nav">
  

  
    <ul id="menu" class="menu">
      
        
        <li class="menu-item menu-item-home">
          <a href="/" rel="section">
            
              <i class="menu-item-icon fa fa-fw fa-home"></i> <br />
            
            Home
          </a>
        </li>
      
        
        <li class="menu-item menu-item-about">
          <a href="/about/" rel="section">
            
              <i class="menu-item-icon fa fa-fw fa-user"></i> <br />
            
            About
          </a>
        </li>
      
        
        <li class="menu-item menu-item-archives">
          <a href="/archives/" rel="section">
            
              <i class="menu-item-icon fa fa-fw fa-archive"></i> <br />
            
            Archives
          </a>
        </li>
      

      
    </ul>
  

  
</nav>



 </div>
    </header>

    <main id="main" class="main">
      <div class="main-inner">
        <div class="content-wrap">
          <div id="content" class="content">
            
  <section id="posts" class="posts-expand">
    
      

  

  
  
  

  <article class="post post-type-normal" itemscope itemtype="http://schema.org/Article">
  
  
  
  <div class="post-block">
    <link itemprop="mainEntityOfPage" href="http://chenghaz.github.io/2018/10/17/semantic-segmantation-2/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="name" content="chenghaz">
      <meta itemprop="description" content="">
      <meta itemprop="image" content="/uploads/avatar.png">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="chenghaz Official 1.0">
    </span>

    
      <header class="post-header">

        
        
          <h1 class="post-title" itemprop="name headline">
                
                <a class="post-title-link" href="/2018/10/17/semantic-segmantation-2/" itemprop="url">Semantic Segmentation Overview (part2)</a></h1>
        

        <div class="post-meta">
          <span class="post-time">
            
              <span class="post-meta-item-icon">
                <i class="fa fa-calendar-o"></i>
              </span>
              
                <span class="post-meta-item-text">Posted on</span>
              
              <time title="Post created" itemprop="dateCreated datePublished" datetime="2018-10-17T11:43:36-07:00">
                2018-10-17
              </time>
            

            

            
          </span>

          

          
            
          

          
          

          

          

          

        </div>
      </header>
    

    
    
    
    <div class="post-body" itemprop="articleBody">

      
      

      
        
          
            <h2 id="Rethinking-Atrous-Convolution-for-Semantic-Image-Segmentation-DeepLabv3"><a href="#Rethinking-Atrous-Convolution-for-Semantic-Image-Segmentation-DeepLabv3" class="headerlink" title="Rethinking Atrous Convolution for Semantic Image Segmentation (DeepLabv3)"></a>Rethinking Atrous Convolution for Semantic Image Segmentation (DeepLabv3)</h2><h3 id="Proposed-Model"><a href="#Proposed-Model" class="headerlink" title="Proposed Model"></a>Proposed Model</h3><p>Applied atrous convolution as the feature extraction method. And employ in cascade or parallel. One advantage of atrous convolution is that it can keep the dimension of each feature map and allow us to extract denser feature responses.</p>
<p>Note that <em>output_stride</em> is the ratio of input image spatial resolution to final output resolution.</p>
<h4 id="Going-Deeper-with-Atrous-Convolution"><a href="#Going-Deeper-with-Atrous-Convolution" class="headerlink" title="Going Deeper with Atrous Convolution"></a>Going Deeper with Atrous Convolution</h4><p>Cascade version of atrous convolution with ResNet architecture. The motivation of this model is that the introduced striding makes it easy to capture long range information in the deeper blocks.<br><img src="/2018/10/17/semantic-segmantation-2/1.png"><br>Also, the author introduced Multi-grid method, which employ a hierarchy of grids of different sizes.<br><img src="/2018/10/17/semantic-segmantation-2/2.png" title="Multigrid Neural Architectures"></p>
<h4 id="Atrous-Spatial-Pyramid-Pooling"><a href="#Atrous-Spatial-Pyramid-Pooling" class="headerlink" title="Atrous Spatial Pyramid Pooling"></a>Atrous Spatial Pyramid Pooling</h4><p>Atrous Spatial Pyrimid Pooling is applied on top of the feature map, with four parallel atrous convolutions with different atrous rates.</p>
<p>Final ASPP: One 1x1 convolution and three 3x3 convolutions with rates(6, 12, 18) when <em>output_stride</em> is 16. Then concat all branches results and pass through another 1x1 convolution before the final 1x1 convolution which generates the final logits. </p>

          
        
      
    </div>
    
    
    

    

    

    

    <footer class="post-footer">
      

      

      

      
      
        <div class="post-eof"></div>
      
    </footer>
  </div>
  
  
  
  </article>


    
      

  

  
  
  

  <article class="post post-type-normal" itemscope itemtype="http://schema.org/Article">
  
  
  
  <div class="post-block">
    <link itemprop="mainEntityOfPage" href="http://chenghaz.github.io/2018/10/15/semantic-segmantation/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="name" content="chenghaz">
      <meta itemprop="description" content="">
      <meta itemprop="image" content="/uploads/avatar.png">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="chenghaz Official 1.0">
    </span>

    
      <header class="post-header">

        
        
          <h1 class="post-title" itemprop="name headline">
                
                <a class="post-title-link" href="/2018/10/15/semantic-segmantation/" itemprop="url">Semantic Segmentation Overview (part1)</a></h1>
        

        <div class="post-meta">
          <span class="post-time">
            
              <span class="post-meta-item-icon">
                <i class="fa fa-calendar-o"></i>
              </span>
              
                <span class="post-meta-item-text">Posted on</span>
              
              <time title="Post created" itemprop="dateCreated datePublished" datetime="2018-10-15T14:49:13-07:00">
                2018-10-15
              </time>
            

            

            
          </span>

          

          
            
          

          
          

          

          

          

        </div>
      </header>
    

    
    
    
    <div class="post-body" itemprop="articleBody">

      
      

      
        
          
            <h2 id="Encoder-Decoder-with-Atrous-Separable-Convolution-for-Semantic-Image-Segmentation"><a href="#Encoder-Decoder-with-Atrous-Separable-Convolution-for-Semantic-Image-Segmentation" class="headerlink" title="Encoder-Decoder with Atrous Separable Convolution for Semantic Image Segmentation"></a>Encoder-Decoder with Atrous Separable Convolution for Semantic Image Segmentation</h2><p>(The model also named DeepLab v3+)</p>
<h3 id="Related-Work"><a href="#Related-Work" class="headerlink" title="Related Work"></a>Related Work</h3><img src="/2018/10/15/semantic-segmantation/1.png">
<ol>
<li><strong>Spatial pyramid pooling</strong>:<br>Models, such as PSPNet or DeepLab, perform spatial pyramid pooling at several grid scales (including image level pooling) or apply several parallel atrous convolution with different rates (called Atrous Spatial Pyramid Pooling, or ASPP).</li>
<li><strong>Encoder-decoder</strong>: Typically, the encoder-decoder networks contain (1) an encoder module that gradually reduces the feature maps and captures higher semantic information, and (2) a decoder module that gradually recovers the spatial information.</li>
</ol>
<h3 id="Proposed-Model"><a href="#Proposed-Model" class="headerlink" title="Proposed Model"></a>Proposed Model</h3><img src="/2018/10/15/semantic-segmantation/2.png">
<p>Encoder-Decoder with Atrous convolution</p>
<h4 id="Atrous-Convolution"><a href="#Atrous-Convolution" class="headerlink" title="Atrous Convolution"></a>Atrous Convolution</h4><img src="/2018/10/15/semantic-segmantation/3.gif" title="https://towardsdatascience.com/types-of-convolutions-in-deep-learning-717013397f4d">
<p>Atrous convolution allows us to explicitly control the resolution of features computed by deep convolutional neural networks and adjust filter’s field-of-view in order to capture multi-scale information, generalizes standard convolution operation.</p>
<h4 id="Depthwise-separable-convolution"><a href="#Depthwise-separable-convolution" class="headerlink" title="Depthwise separable convolution"></a>Depthwise separable convolution</h4><p>Like MobileNet or MobileNetV2</p>
<h4 id="Encoder-DeepLab-v3"><a href="#Encoder-DeepLab-v3" class="headerlink" title="Encoder: DeepLab v3"></a>Encoder: DeepLab v3</h4><p>Use the last feature map before logits in the original DeepLabv3 as the encoder output in our proposed encoder-decoder structure. Also, author mentioned a output stride as a Hyperparameter, which means the size relationship between original image and output feature map.</p>
<h4 id="Decoder"><a href="#Decoder" class="headerlink" title="Decoder"></a>Decoder</h4><p>The naive bilinear upsample cannot recover semantic details of an image. The author mentioned a method that combine bilinear upsample and convolution together.<br>The decoder work flow for DeepLab v3+ is: upsample -&gt; concat selected low level feature -&gt; convolution -&gt; upsample -&gt; result</p>
<h4 id="Xception"><a href="#Xception" class="headerlink" title="Xception"></a>Xception</h4><p>One of the backbone model.</p>
<h2 id="PARSENET-LOOKING-WIDER-TO-SEE-BETTER"><a href="#PARSENET-LOOKING-WIDER-TO-SEE-BETTER" class="headerlink" title="PARSENET: LOOKING WIDER TO SEE BETTER"></a>PARSENET: LOOKING WIDER TO SEE BETTER</h2><ul>
<li>FCN disregards global information about an image, thus ignoring potentially useful scene-level semantic context</li>
<li>CRF(conditional random field) &amp; DNN require a fair amount of experience in managing the idiosyncrasies of training methodology and parameters.</li>
</ul>
<h3 id="Model-ParseNet"><a href="#Model-ParseNet" class="headerlink" title="Model - ParseNet"></a>Model - ParseNet</h3><h4 id="Global-context"><a href="#Global-context" class="headerlink" title="Global context"></a>Global context</h4><p>Context is known to be very useful for improving performance on detection and segmentation tasks using deep learning. However, in practice, for FCN, the empirical size of the receptive fields is much smaller, and is not enough to capture the global context. The author proposed a global average pooling and pool the context features from the last layer or any layer if that is desired. Then concat global feature to feature map to combine the global context to model.</p>
<h4 id="Early-Fusion-and-Late-Fusion"><a href="#Early-Fusion-and-Late-Fusion" class="headerlink" title="Early Fusion and Late Fusion"></a>Early Fusion and Late Fusion</h4><ul>
<li>Early fusion: unpool (replicate) global feature to the same size as of local feature map spatially and then concatenate them.</li>
<li>Late fusion: each feature is used to learn its own classifier, followed by merging the two predictions into a single classification score.</li>
</ul>
<h4 id="l2-normalization-layer"><a href="#l2-normalization-layer" class="headerlink" title="l2 normalization layer"></a>l2 normalization layer</h4><p>Naively concatenating features leads to poor performance as the ”larger” features dominate the ”smaller” ones. The author applied L2-norm and learned the scale parameter for each channel before using the feature for classification, which leads to more stable training. The author mentioned l2-norm on each pixel on feature map instead of whole feature map.</p>
<h2 id="TBD"><a href="#TBD" class="headerlink" title="TBD"></a>TBD</h2><ol>
<li>DeepLab v3</li>
<li>Xception</li>
</ol>

          
        
      
    </div>
    
    
    

    

    

    

    <footer class="post-footer">
      

      

      

      
      
        <div class="post-eof"></div>
      
    </footer>
  </div>
  
  
  
  </article>


    
      

  

  
  
  

  <article class="post post-type-normal" itemscope itemtype="http://schema.org/Article">
  
  
  
  <div class="post-block">
    <link itemprop="mainEntityOfPage" href="http://chenghaz.github.io/2018/09/09/tf-object-detection-2/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="name" content="chenghaz">
      <meta itemprop="description" content="">
      <meta itemprop="image" content="/uploads/avatar.png">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="chenghaz Official 1.0">
    </span>

    
      <header class="post-header">

        
        
          <h1 class="post-title" itemprop="name headline">
                
                <a class="post-title-link" href="/2018/09/09/tf-object-detection-2/" itemprop="url">Reading note for tensorflow/models/research/object_detection (part2)</a></h1>
        

        <div class="post-meta">
          <span class="post-time">
            
              <span class="post-meta-item-icon">
                <i class="fa fa-calendar-o"></i>
              </span>
              
                <span class="post-meta-item-text">Posted on</span>
              
              <time title="Post created" itemprop="dateCreated datePublished" datetime="2018-09-09T22:55:40-07:00">
                2018-09-09
              </time>
            

            

            
          </span>

          

          
            
          

          
          

          

          

          

        </div>
      </header>
    

    
    
    
    <div class="post-body" itemprop="articleBody">

      
      

      
        
          
            <h2 id="Reading-note-for-tensorflow-models-research-object-detection-part2"><a href="#Reading-note-for-tensorflow-models-research-object-detection-part2" class="headerlink" title="Reading note for tensorflow/models/research/object_detection (part2)"></a>Reading note for tensorflow/models/research/object_detection (part2)</h2><h3 id="Path-for-training-start-from-model-main-py"><a href="#Path-for-training-start-from-model-main-py" class="headerlink" title="Path for training: start from model_main.py"></a>Path for training: start from model_main.py</h3><p>First, we need to specify a config file: <a href="https://github.com/tensorflow/models/blob/master/research/object_detection/g3doc/configuring_jobs.md" target="_blank" rel="noopener">official document</a>.<br>It contains several parts: model, train_config, train_input_reader, eval_config, eval_input_reader. Now we move to main function.<br><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># Config file we specified before</span></span><br><span class="line">flags.DEFINE_string(<span class="string">'pipeline_config_path'</span>, <span class="keyword">None</span>, <span class="string">'Path to pipeline config file.'</span>)</span><br><span class="line">...</span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">main</span><span class="params">(unused_argv)</span>:</span></span><br><span class="line">  ...</span><br><span class="line">  train_and_eval_dict = model_lib.create_estimator_and_inputs(</span><br><span class="line">    run_config=config,</span><br><span class="line">    hparams=model_hparams.create_hparams(FLAGS.hparams_overrides),</span><br><span class="line">    pipeline_config_path=FLAGS.pipeline_config_path,</span><br><span class="line">    train_steps=FLAGS.num_train_steps,</span><br><span class="line">    eval_steps=FLAGS.num_eval_steps)</span><br></pre></td></tr></table></figure></p>
<h3 id="File-model-lib-py-gt-help-functions-for-model-main-py"><a href="#File-model-lib-py-gt-help-functions-for-model-main-py" class="headerlink" title="File model_lib.py -&gt; help functions for model_main.py"></a>File model_lib.py -&gt; help functions for model_main.py</h3><p>jump to <em>model_lib.create_estimator_and_inputs</em> function<br><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">create_estimator_and_inputs</span><span class="params">(run_config,</span></span></span><br><span class="line"><span class="function"><span class="params">                                hparams,</span></span></span><br><span class="line"><span class="function"><span class="params">                                pipeline_config_path,</span></span></span><br><span class="line"><span class="function"><span class="params">                                train_steps=None,</span></span></span><br><span class="line"><span class="function"><span class="params">                                eval_steps=None,</span></span></span><br><span class="line"><span class="function"><span class="params">                                model_fn_creator=create_model_fn,</span></span></span><br><span class="line"><span class="function"><span class="params">                                use_tpu_estimator=False,</span></span></span><br><span class="line"><span class="function"><span class="params">                                use_tpu=False,</span></span></span><br><span class="line"><span class="function"><span class="params">                                num_shards=<span class="number">1</span>,</span></span></span><br><span class="line"><span class="function"><span class="params">                                params=None,</span></span></span><br><span class="line"><span class="function"><span class="params">                                **kwargs)</span>:</span></span><br><span class="line">  <span class="comment">#  Map methods</span></span><br><span class="line">  <span class="comment"># 'get_configs_from_pipeline_file': config_util.get_configs_from_pipeline_file</span></span><br><span class="line">  <span class="comment"># This function is just read pipeline file into protobuf</span></span><br><span class="line">  get_configs_from_pipeline_file = MODEL_BUILD_UTIL_MAP[</span><br><span class="line">    <span class="string">'get_configs_from_pipeline_file'</span>]</span><br><span class="line">  <span class="comment"># 'merge_external_params_with_configs': config_util.merge_external_params_with_configs</span></span><br><span class="line">  merge_external_params_with_configs = MODEL_BUILD_UTIL_MAP[</span><br><span class="line">    <span class="string">'merge_external_params_with_configs'</span>]</span><br><span class="line">  <span class="comment"># 'create_pipeline_proto_from_configs': config_util.create_pipeline_proto_from_configs</span></span><br><span class="line">  create_pipeline_proto_from_configs = MODEL_BUILD_UTIL_MAP[</span><br><span class="line">    <span class="string">'create_pipeline_proto_from_configs'</span>]</span><br><span class="line">  <span class="comment">####################################################################</span></span><br><span class="line">  <span class="comment"># -&gt; jump to config_util.create_pipeline_proto_from_configs function</span></span><br><span class="line">  <span class="comment">####################################################################</span></span><br><span class="line">  pipeline_config = pipeline_pb2.TrainEvalPipelineConfig()</span><br><span class="line">  pipeline_config.model.CopyFrom(configs[<span class="string">"model"</span>])</span><br><span class="line">  pipeline_config.train_config.CopyFrom(configs[<span class="string">"train_config"</span>])</span><br><span class="line">  pipeline_config.train_input_reader.CopyFrom(configs[<span class="string">"train_input_config"</span>])</span><br><span class="line">  pipeline_config.eval_config.CopyFrom(configs[<span class="string">"eval_config"</span>])</span><br><span class="line">  pipeline_config.eval_input_reader.CopyFrom(configs[<span class="string">"eval_input_config"</span>])</span><br><span class="line">  <span class="comment">####################################################################</span></span><br><span class="line">  <span class="comment"># -&gt; back to create_estimator_and_inputs function</span></span><br><span class="line">  <span class="comment">####################################################################</span></span><br><span class="line">  <span class="comment"># Map methods</span></span><br><span class="line">  <span class="comment"># 'create_train_input_fn': inputs.create_train_input_fn,</span></span><br><span class="line">  create_train_input_fn = MODEL_BUILD_UTIL_MAP[<span class="string">'create_train_input_fn'</span>]</span><br><span class="line">  <span class="comment"># 'create_eval_input_fn': inputs.create_eval_input_fn,</span></span><br><span class="line">  create_eval_input_fn = MODEL_BUILD_UTIL_MAP[<span class="string">'create_eval_input_fn'</span>]</span><br><span class="line">  <span class="comment"># 'create_predict_input_fn': inputs.create_predict_input_fn,</span></span><br><span class="line">  create_predict_input_fn = MODEL_BUILD_UTIL_MAP[<span class="string">'create_predict_input_fn'</span>]</span><br><span class="line">  ...</span><br><span class="line">  <span class="comment"># assign variables &amp; make configs</span></span><br><span class="line">  ...</span><br><span class="line">  <span class="comment"># model_builder.build is IMPORTANT, IMPORTANT, IMPORTANT</span></span><br><span class="line">  detection_model_fn = functools.partial(</span><br><span class="line">    model_builder.build, model_config=model_config)</span><br><span class="line">  ...</span><br><span class="line">  <span class="comment"># Here create_train_input_fn function returns a</span></span><br><span class="line">  <span class="comment"># tf.data.Dataset that holds (features, labels) tuple</span></span><br><span class="line">  train_input_fn = create_train_input_fn(</span><br><span class="line">    train_config=train_config,</span><br><span class="line">    train_input_config=train_input_config,</span><br><span class="line">    model_config=model_config)</span><br><span class="line">  ...</span><br><span class="line">  model_fn = model_fn_creator(detection_model_fn, configs, hparams, use_tpu)</span><br><span class="line">  ...</span><br></pre></td></tr></table></figure></p>
<h3 id="File-model-builder-py-gt-build-DetectionModel"><a href="#File-model-builder-py-gt-build-DetectionModel" class="headerlink" title="File model_builder.py -&gt; build DetectionModel"></a>File model_builder.py -&gt; build DetectionModel</h3><p>Start from build function<br><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">build</span><span class="params">(model_config, is_training, add_summaries=True,</span></span></span><br><span class="line"><span class="function"><span class="params">          add_background_class=True)</span>:</span></span><br><span class="line">  <span class="comment"># Here, we use faster_rcnn_meta_arch as our model</span></span><br><span class="line">  <span class="keyword">if</span> <span class="keyword">not</span> isinstance(model_config, model_pb2.DetectionModel):</span><br><span class="line">  <span class="keyword">raise</span> ValueError(<span class="string">'model_config not of type model_pb2.DetectionModel.'</span>)</span><br><span class="line">  meta_architecture = model_config.WhichOneof(<span class="string">'model'</span>)</span><br><span class="line">  <span class="keyword">if</span> meta_architecture == <span class="string">'ssd'</span>:</span><br><span class="line">    <span class="keyword">return</span> _build_ssd_model(model_config.ssd, is_training, add_summaries,</span><br><span class="line">                            add_background_class)</span><br><span class="line">  <span class="keyword">if</span> meta_architecture == <span class="string">'faster_rcnn'</span>:</span><br><span class="line">    <span class="keyword">return</span> _build_faster_rcnn_model(model_config.faster_rcnn, is_training,</span><br><span class="line">                                    add_summaries)</span><br><span class="line">  <span class="keyword">raise</span> ValueError(<span class="string">'Unknown meta architecture: &#123;&#125;'</span>.format(meta_architecture))</span><br></pre></td></tr></table></figure></p>
<p>_build_faster_rcnn_model - <strong>Important function</strong><br><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br><span class="line">71</span><br><span class="line">72</span><br><span class="line">73</span><br><span class="line">74</span><br><span class="line">75</span><br><span class="line">76</span><br><span class="line">77</span><br><span class="line">78</span><br><span class="line">79</span><br><span class="line">80</span><br><span class="line">81</span><br><span class="line">82</span><br><span class="line">83</span><br><span class="line">84</span><br><span class="line">85</span><br><span class="line">86</span><br><span class="line">87</span><br><span class="line">88</span><br><span class="line">89</span><br><span class="line">90</span><br><span class="line">91</span><br><span class="line">92</span><br><span class="line">93</span><br><span class="line">94</span><br><span class="line">95</span><br><span class="line">96</span><br><span class="line">97</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">_build_faster_rcnn_model</span><span class="params">(frcnn_config, is_training, add_summaries)</span>:</span></span><br><span class="line">  num_classes = frcnn_config.num_classes</span><br><span class="line">  image_resizer_fn = image_resizer_builder.build(frcnn_config.image_resizer)</span><br><span class="line"></span><br><span class="line">  <span class="comment"># Assign a feature extraction method for detection model. e.g. ResNet101</span></span><br><span class="line">  <span class="comment"># Resnet: nets.resnet_v1</span></span><br><span class="line">  feature_extractor = _build_faster_rcnn_feature_extractor(</span><br><span class="line">      frcnn_config.feature_extractor, is_training,</span><br><span class="line">      frcnn_config.inplace_batchnorm_update)</span><br><span class="line"></span><br><span class="line">  number_of_stages = frcnn_config.number_of_stages</span><br><span class="line">  first_stage_anchor_generator = anchor_generator_builder.build(</span><br><span class="line">      frcnn_config.first_stage_anchor_generator)</span><br><span class="line"></span><br><span class="line">  <span class="comment"># Several hyperparameters for first stage  </span></span><br><span class="line">  first_stage_target_assigner = target_assigner.create_target_assigner(</span><br><span class="line">    <span class="string">'FasterRCNN'</span>,</span><br><span class="line">    <span class="string">'proposal'</span>,</span><br><span class="line">    use_matmul_gather=frcnn_config.use_matmul_gather_in_matcher)</span><br><span class="line">  first_stage_atrous_rate = frcnn_config.first_stage_atrous_rate</span><br><span class="line">  first_stage_box_predictor_arg_scope_fn = hyperparams_builder.build(</span><br><span class="line">    frcnn_config.first_stage_box_predictor_conv_hyperparams, is_training)</span><br><span class="line">  first_stage_box_predictor_kernel_size = (</span><br><span class="line">    frcnn_config.first_stage_box_predictor_kernel_size)</span><br><span class="line">  first_stage_box_predictor_depth = frcnn_config.first_stage_box_predictor_depth</span><br><span class="line">  first_stage_minibatch_size = frcnn_config.first_stage_minibatch_size</span><br><span class="line">  first_stage_sampler = sampler.BalancedPositiveNegativeSampler(</span><br><span class="line">    positive_fraction=frcnn_config.first_stage_positive_balance_fraction,</span><br><span class="line">    is_static=frcnn_config.use_static_balanced_label_sampler)</span><br><span class="line">  first_stage_nms_score_threshold = frcnn_config.first_stage_nms_score_threshold</span><br><span class="line">  first_stage_nms_iou_threshold = frcnn_config.first_stage_nms_iou_threshold</span><br><span class="line">  first_stage_max_proposals = frcnn_config.first_stage_max_proposals</span><br><span class="line">  first_stage_loc_loss_weight = (</span><br><span class="line">    frcnn_config.first_stage_localization_loss_weight)</span><br><span class="line">  first_stage_obj_loss_weight = frcnn_config.first_stage_objectness_loss_weight</span><br><span class="line"></span><br><span class="line">  initial_crop_size = frcnn_config.initial_crop_size</span><br><span class="line">  maxpool_kernel_size = frcnn_config.maxpool_kernel_size</span><br><span class="line">  maxpool_stride = frcnn_config.maxpool_stride</span><br><span class="line"></span><br><span class="line">  <span class="comment"># Several hyperparameters for second stage</span></span><br><span class="line">  second_stage_target_assigner = target_assigner.create_target_assigner(</span><br><span class="line">    <span class="string">'FasterRCNN'</span>,</span><br><span class="line">    <span class="string">'detection'</span>,</span><br><span class="line">    use_matmul_gather=frcnn_config.use_matmul_gather_in_matcher)</span><br><span class="line">  second_stage_box_predictor = box_predictor_builder.build(</span><br><span class="line">    hyperparams_builder.build,</span><br><span class="line">    frcnn_config.second_stage_box_predictor,</span><br><span class="line">    is_training=is_training,</span><br><span class="line">    num_classes=num_classes)</span><br><span class="line">  second_stage_batch_size = frcnn_config.second_stage_batch_size</span><br><span class="line">  second_stage_sampler = sampler.BalancedPositiveNegativeSampler(</span><br><span class="line">    positive_fraction=frcnn_config.second_stage_balance_fraction,</span><br><span class="line">    is_static=frcnn_config.use_static_balanced_label_sampler)</span><br><span class="line">  <span class="comment"># NMS for second stage is different API from first stage</span></span><br><span class="line">  <span class="comment"># But they point to the same function. post_processing.batch_multiclass_non_max_suppression</span></span><br><span class="line">  (second_stage_non_max_suppression_fn, second_stage_score_conversion_fn</span><br><span class="line">  ) = post_processing_builder.build(frcnn_config.second_stage_post_processing)</span><br><span class="line">  second_stage_localization_loss_weight = (</span><br><span class="line">    frcnn_config.second_stage_localization_loss_weight)</span><br><span class="line">  second_stage_classification_loss = (</span><br><span class="line">    losses_builder.build_faster_rcnn_classification_loss(</span><br><span class="line">        frcnn_config.second_stage_classification_loss))</span><br><span class="line">  second_stage_classification_loss_weight = (</span><br><span class="line">    frcnn_config.second_stage_classification_loss_weight)</span><br><span class="line">  second_stage_mask_prediction_loss_weight = (</span><br><span class="line">    frcnn_config.second_stage_mask_prediction_loss_weight)</span><br><span class="line"></span><br><span class="line">  hard_example_miner = <span class="keyword">None</span></span><br><span class="line">  <span class="keyword">if</span> frcnn_config.HasField(<span class="string">'hard_example_miner'</span>):</span><br><span class="line">    hard_example_miner = losses_builder.build_hard_example_miner(</span><br><span class="line">      frcnn_config.hard_example_miner,</span><br><span class="line">      second_stage_classification_loss_weight,</span><br><span class="line">      second_stage_localization_loss_weight)</span><br><span class="line"></span><br><span class="line">  use_matmul_crop_and_resize = (frcnn_config.use_matmul_crop_and_resize)</span><br><span class="line">  clip_anchors_to_image = (</span><br><span class="line">    frcnn_config.clip_anchors_to_image)</span><br><span class="line"></span><br><span class="line">  common_kwargs = &#123;</span><br><span class="line">    ...</span><br><span class="line">  &#125;</span><br><span class="line"></span><br><span class="line">  <span class="keyword">if</span> isinstance(second_stage_box_predictor,</span><br><span class="line">              rfcn_box_predictor.RfcnBoxPredictor):</span><br><span class="line">    <span class="keyword">return</span> rfcn_meta_arch.RFCNMetaArch(</span><br><span class="line">      second_stage_rfcn_box_predictor=second_stage_box_predictor,</span><br><span class="line">      **common_kwargs)</span><br><span class="line">  <span class="keyword">else</span>:</span><br><span class="line">    <span class="keyword">return</span> faster_rcnn_meta_arch.FasterRCNNMetaArch(</span><br><span class="line">      initial_crop_size=initial_crop_size,</span><br><span class="line">      maxpool_kernel_size=maxpool_kernel_size,</span><br><span class="line">      maxpool_stride=maxpool_stride,</span><br><span class="line">      second_stage_mask_rcnn_box_predictor=second_stage_box_predictor,</span><br><span class="line">      second_stage_mask_prediction_loss_weight=(</span><br><span class="line">          second_stage_mask_prediction_loss_weight),</span><br><span class="line">      **common_kwargs)</span><br></pre></td></tr></table></figure></p>
<p>The faster_rcnn_meta_arch is returned by this function</p>
<h3 id="Back-to-model-main-py"><a href="#Back-to-model-main-py" class="headerlink" title="Back to model_main.py"></a>Back to model_main.py</h3><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br></pre></td><td class="code"><pre><span class="line">...</span><br><span class="line"><span class="keyword">else</span>:</span><br><span class="line">  train_spec, eval_specs = model_lib.create_train_and_eval_specs(</span><br><span class="line">    train_input_fn,</span><br><span class="line">    eval_input_fn,</span><br><span class="line">    eval_on_train_input_fn,</span><br><span class="line">    predict_input_fn,</span><br><span class="line">    train_steps,</span><br><span class="line">    eval_steps,</span><br><span class="line">    eval_on_train_data=<span class="keyword">False</span>)</span><br><span class="line"><span class="comment">#############################################################</span></span><br><span class="line"><span class="comment"># -&gt; jump to model.lib.create_train_and_eval_specs</span></span><br><span class="line"><span class="comment">#############################################################</span></span><br><span class="line">...</span><br><span class="line">train_spec = tf.estimator.TrainSpec(</span><br><span class="line">  input_fn=train_input_fn, max_steps=train_steps)</span><br><span class="line"></span><br><span class="line">eval_specs = [</span><br><span class="line">  tf.estimator.EvalSpec(</span><br><span class="line">      name=eval_spec_name,</span><br><span class="line">      input_fn=eval_input_fn,</span><br><span class="line">      steps=eval_steps,</span><br><span class="line">      exporters=exporter)</span><br><span class="line">]</span><br><span class="line">...</span><br></pre></td></tr></table></figure>

          
        
      
    </div>
    
    
    

    

    

    

    <footer class="post-footer">
      

      

      

      
      
        <div class="post-eof"></div>
      
    </footer>
  </div>
  
  
  
  </article>


    
      

  

  
  
  

  <article class="post post-type-normal" itemscope itemtype="http://schema.org/Article">
  
  
  
  <div class="post-block">
    <link itemprop="mainEntityOfPage" href="http://chenghaz.github.io/2018/09/06/tf-object-detection-1/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="name" content="chenghaz">
      <meta itemprop="description" content="">
      <meta itemprop="image" content="/uploads/avatar.png">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="chenghaz Official 1.0">
    </span>

    
      <header class="post-header">

        
        
          <h1 class="post-title" itemprop="name headline">
                
                <a class="post-title-link" href="/2018/09/06/tf-object-detection-1/" itemprop="url">Reading note for tensorflow/models/research/object_detection (part1)</a></h1>
        

        <div class="post-meta">
          <span class="post-time">
            
              <span class="post-meta-item-icon">
                <i class="fa fa-calendar-o"></i>
              </span>
              
                <span class="post-meta-item-text">Posted on</span>
              
              <time title="Post created" itemprop="dateCreated datePublished" datetime="2018-09-06T18:38:46-07:00">
                2018-09-06
              </time>
            

            

            
          </span>

          

          
            
          

          
          

          

          

          

        </div>
      </header>
    

    
    
    
    <div class="post-body" itemprop="articleBody">

      
      

      
        
          
            <h3 id="Start-from-Faster-RCNN"><a href="#Start-from-Faster-RCNN" class="headerlink" title="Start from Faster-RCNN"></a>Start from Faster-RCNN</h3><h4 id="File-meta-architectures-faster-rcnn-meta-arch-py"><a href="#File-meta-architectures-faster-rcnn-meta-arch-py" class="headerlink" title="File: meta_architectures/faster_rcnn_meta_arch.py"></a>File: meta_architectures/faster_rcnn_meta_arch.py</h4><p>For FasterRCNNMetaArch class, first Step is fully understand all Args meaning<br><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">FasterRCNNMetaArch</span><span class="params">(model.DetectionModel)</span></span></span><br></pre></td></tr></table></figure></p>
<p>init: The init function is to assign a lot of hyperparameters or functions<br><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">__init__</span><span class="params">(...)</span>:</span></span><br><span class="line">  self._first_stage_box_predictor =</span><br><span class="line">      box_predictor_builder.build_convolutional_box_predictor</span><br><span class="line">  self._second_stage_nms_fn = second_stage_non_max_suppression_fn</span><br></pre></td></tr></table></figure></p>
<p>preprocess: Notice that the base function of preprocess function is at “core/model.py”. The main purpose of this function is to do input preprocessing: resizing and scaling<br><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">preprocess</span><span class="params">(self, inputs)</span>:</span></span><br><span class="line">  <span class="keyword">if</span> inputs.dtype <span class="keyword">is</span> <span class="keyword">not</span> tf.float32:</span><br><span class="line">    <span class="keyword">raise</span> ValueError(<span class="string">'`preprocess` expects a tf.float32 tensor'</span>)</span><br><span class="line">    <span class="keyword">with</span> tf.name_scope(<span class="string">'Preprocessor'</span>):</span><br><span class="line">      outputs = shape_utils.static_or_dynamic_map_fn(</span><br><span class="line">        self._image_resizer_fn,</span><br><span class="line">        elems=inputs,</span><br><span class="line">        dtype=[tf.float32, tf.int32],</span><br><span class="line">        parallel_iterations=self._parallel_iterations)</span><br><span class="line">      resized_inputs = outputs[<span class="number">0</span>]</span><br><span class="line">      true_image_shapes = outputs[<span class="number">1</span>]</span><br><span class="line">      <span class="keyword">return</span> (self._feature_extractor.preprocess(resized_inputs),</span><br><span class="line">        true_image_shapes)</span><br></pre></td></tr></table></figure></p>
<p>predict: Predicts unpostprocessed tensors from input tensor. From the comment, the authors mentioned “to yield “raw” un-postprocessed predictions. e.g. RPN predictions”<br><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">predict</span><span class="params">(self, preprocessed_inputs, true_image_shapes)</span>:</span></span><br><span class="line">  <span class="comment"># --- The explanation of these two functions is below ---</span></span><br><span class="line">  (rpn_box_predictor_features, rpn_features_to_crop, anchors_boxlist,</span><br><span class="line">    image_shape) = self._extract_rpn_feature_maps(preprocessed_inputs)</span><br><span class="line">  (rpn_box_encodings, rpn_objectness_predictions_with_background</span><br><span class="line">    ) = self._predict_rpn_proposals(rpn_box_predictor_features)  </span><br><span class="line">  <span class="comment"># The Faster R-CNN paper recommends pruning anchors that venture outside</span></span><br><span class="line">  <span class="comment"># the image window at training time and clipping at inference time.</span></span><br><span class="line">  clip_window = tf.to_float(tf.stack([<span class="number">0</span>, <span class="number">0</span>, image_shape[<span class="number">1</span>], image_shape[<span class="number">2</span>]]))</span><br><span class="line">  <span class="keyword">if</span> self._is_training:</span><br><span class="line">    ...</span><br><span class="line">    ...</span><br><span class="line">  ...</span><br><span class="line">  <span class="keyword">if</span> self._number_of_stages &gt;= <span class="number">2</span>:</span><br><span class="line">    <span class="comment"># --- The explanation of _predict_second_stage function is below ---</span></span><br><span class="line">    prediction_dict.update(self._predict_second_stage(</span><br><span class="line">        rpn_box_encodings,</span><br><span class="line">        rpn_objectness_predictions_with_background,</span><br><span class="line">        rpn_features_to_crop,</span><br><span class="line">        self._anchors.get(), image_shape, true_image_shapes))</span><br><span class="line"></span><br><span class="line">  <span class="keyword">if</span> self._number_of_stages == <span class="number">3</span>:</span><br><span class="line">    <span class="comment"># --- _predict_third_stage predicts non-box non-class outputs ---</span></span><br><span class="line">    <span class="comment"># e.g. mask prediction</span></span><br><span class="line">    prediction_dict = self._predict_third_stage(</span><br><span class="line">        prediction_dict, true_image_shapes)</span><br><span class="line"></span><br><span class="line">  <span class="keyword">return</span> ...</span><br></pre></td></tr></table></figure></p>
<p>_extract_rpn_feature_maps: Just extract RPN features. Notice that we have two features maps here: <em>rpn_box_predictor_features and rpn_features_to_crop</em>.<br><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">_extract_rpn_feature_maps</span><span class="params">(self, preprocessed_inputs)</span>:</span></span><br><span class="line">    ...</span><br><span class="line">  <span class="comment"># rpn_features_to_crop is like the feature before RPN</span></span><br><span class="line">  rpn_features_to_crop, _ = self._feature_extractor.extract_proposal_features(</span><br><span class="line">    preprocessed_inputs, scope=self.first_stage_feature_extractor_scope)</span><br><span class="line">    ...</span><br><span class="line">  <span class="comment"># Then feed rpn_features_to_crop to conv2d to get rpn_box_predictor_features</span></span><br><span class="line">  <span class="keyword">with</span> slim.arg_scope(self._first_stage_box_predictor_arg_scope_fn()):</span><br><span class="line">    kernel_size = self._first_stage_box_predictor_kernel_size</span><br><span class="line">    rpn_box_predictor_features = slim.conv2d(</span><br><span class="line">      rpn_features_to_crop,</span><br><span class="line">      self._first_stage_box_predictor_depth,</span><br><span class="line">      kernel_size=[kernel_size, kernel_size],</span><br><span class="line">      rate=self._first_stage_atrous_rate,</span><br><span class="line">      activation_fn=tf.nn.relu6)</span><br><span class="line">    ...</span><br></pre></td></tr></table></figure></p>
<p>_predict_rpn_proposals: Box predictors after RPN feature map to predict proposals. The input here is <em>rpn_box_predictor_features</em> and output is <em>box_encoding: 3-D tensor of float - predict boxes</em> and <em>object predictions: 3-D tensors - class prediction</em><br><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">_predict_rpn_proposals</span><span class="params">(self, rpn_box_predictor_features)</span>:</span></span><br><span class="line">  num_anchors_per_location = (</span><br><span class="line">    self._first_stage_anchor_generator.num_anchors_per_location())</span><br><span class="line">  <span class="keyword">if</span> len(num_anchors_per_location) != <span class="number">1</span>:</span><br><span class="line">    <span class="keyword">raise</span> RuntimeError(<span class="string">'anchor_generator is expected to generate anchors '</span></span><br><span class="line">                   <span class="string">'corresponding to a single feature map.'</span>)</span><br><span class="line">  <span class="keyword">if</span> self._first_stage_box_predictor.is_keras_model:</span><br><span class="line">    box_predictions = self._first_stage_box_predictor(</span><br><span class="line">        [rpn_box_predictor_features])</span><br><span class="line">  <span class="keyword">else</span>:</span><br><span class="line">    <span class="comment"># The _first_stage_box_predictor is assigned at __init__</span></span><br><span class="line">    box_predictions = self._first_stage_box_predictor.predict(</span><br><span class="line">        [rpn_box_predictor_features],</span><br><span class="line">        num_anchors_per_location,</span><br><span class="line">        scope=self.first_stage_box_predictor_scope)</span><br><span class="line">  <span class="comment"># box infomation and class information</span></span><br><span class="line">  box_encodings = tf.concat(</span><br><span class="line">        box_predictions[box_predictor.BOX_ENCODINGS], axis=<span class="number">1</span>)</span><br><span class="line">  objectness_predictions_with_background = tf.concat(</span><br><span class="line">      box_predictions[box_predictor.CLASS_PREDICTIONS_WITH_BACKGROUND],</span><br><span class="line">      axis=<span class="number">1</span>)</span><br><span class="line">  <span class="keyword">return</span> (tf.squeeze(box_encodings, axis=<span class="number">2</span>),</span><br><span class="line">          objectness_predictions_with_background)</span><br></pre></td></tr></table></figure></p>
<p>_predict_second_stage: Predicts the output tensor from second stage of Faster R-CNN. This function is similar to function <em>predict</em>.<br><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">_predict_second_stage</span><span class="params">(self, rpn_box_encodings,</span></span></span><br><span class="line"><span class="function"><span class="params">                          rpn_objectness_predictions_with_background,</span></span></span><br><span class="line"><span class="function"><span class="params">                          rpn_features_to_crop,</span></span></span><br><span class="line"><span class="function"><span class="params">                          anchors,</span></span></span><br><span class="line"><span class="function"><span class="params">                          image_shape,</span></span></span><br><span class="line"><span class="function"><span class="params">                          true_image_shapes)</span>:</span></span><br><span class="line">  image_shape_2d = self._image_batch_shape_2d(image_shape)</span><br><span class="line">  <span class="comment"># --- _postprocess_rpn contains first_stage_nms ---</span></span><br><span class="line">  <span class="comment"># --- explanation below ---</span></span><br><span class="line">  proposal_boxes_normalized, _, num_proposals = self._postprocess_rpn(</span><br><span class="line">      rpn_box_encodings, rpn_objectness_predictions_with_background,</span><br><span class="line">      anchors, image_shape_2d, true_image_shapes)</span><br><span class="line">  <span class="comment"># Resize the first stage RPN feature then maxpool</span></span><br><span class="line">  <span class="comment"># RoI pooling function</span></span><br><span class="line">  flattened_proposal_feature_maps = (</span><br><span class="line">      self._compute_second_stage_input_feature_maps(</span><br><span class="line">          rpn_features_to_crop, proposal_boxes_normalized))</span><br><span class="line">  <span class="comment"># Extract second stage box classifier feature</span></span><br><span class="line">  <span class="comment"># Similar to _extract_rpn_feature_maps</span></span><br><span class="line">  box_classifier_features = (</span><br><span class="line">      self._feature_extractor.extract_box_classifier_features(</span><br><span class="line">          flattened_proposal_feature_maps,</span><br><span class="line">          scope=self.second_stage_feature_extractor_scope))</span><br><span class="line">  <span class="comment"># Second Stage box predictor</span></span><br><span class="line">  <span class="keyword">if</span> self._mask_rcnn_box_predictor.is_keras_model:</span><br><span class="line">    box_predictions = self._mask_rcnn_box_predictor(</span><br><span class="line">      [box_classifier_features],</span><br><span class="line">      prediction_stage=<span class="number">2</span>)</span><br><span class="line">  <span class="keyword">else</span>:</span><br><span class="line">    <span class="comment"># ._mask_rcnn_box_predictor is second_stage_mask_rcnn_box_predictor</span></span><br><span class="line">    <span class="comment"># at __init__. Then, from faster_rcnn_meta_arch_test_lib</span></span><br><span class="line">    <span class="comment"># second_stage_mask_rcnn_box_predictor is box_predictor *core/box_predictor.py*</span></span><br><span class="line">    box_predictions = self._mask_rcnn_box_predictor.predict(</span><br><span class="line">      [box_classifier_features],</span><br><span class="line">      num_predictions_per_location=[<span class="number">1</span>],</span><br><span class="line">      scope=self.second_stage_box_predictor_scope,</span><br><span class="line">      prediction_stage=<span class="number">2</span>)</span><br><span class="line">  <span class="comment"># box information and class information</span></span><br><span class="line">  refined_box_encodings = tf.squeeze(</span><br><span class="line">    box_predictions[box_predictor.BOX_ENCODINGS],</span><br><span class="line">    axis=<span class="number">1</span>, name=<span class="string">'all_refined_box_encodings'</span>)</span><br><span class="line">  class_predictions_with_background = tf.squeeze(</span><br><span class="line">    box_predictions[box_predictor.CLASS_PREDICTIONS_WITH_BACKGROUND],</span><br><span class="line">    axis=<span class="number">1</span>, name=<span class="string">'all_class_predictions_with_background'</span>)</span><br><span class="line">  ...</span><br><span class="line">  <span class="keyword">return</span> ...</span><br></pre></td></tr></table></figure></p>
<p>_postprocess_rpn: convert RPN to proposals, perform non max suppression(NMS). This function contains many tensorflow shape API. Here, I just select the functional part.<br><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">_postprocess_rpn</span><span class="params">(self,</span></span></span><br><span class="line"><span class="function"><span class="params">                    rpn_box_encodings_batch,</span></span></span><br><span class="line"><span class="function"><span class="params">                    rpn_objectness_predictions_with_background_batch,</span></span></span><br><span class="line"><span class="function"><span class="params">                    anchors,</span></span></span><br><span class="line"><span class="function"><span class="params">                    image_shapes,</span></span></span><br><span class="line"><span class="function"><span class="params">                    true_image_shapes)</span>:</span></span><br><span class="line">  <span class="comment"># tf.expand_dims tf.tile tf.squeeze tf.nn.softmax ...</span></span><br><span class="line">  ...</span><br><span class="line">  (proposal_boxes, proposal_scores, _, _, _,</span><br><span class="line">  <span class="comment"># The NMS here is post_processing.batch_multiclass_non_max_suppression</span></span><br><span class="line">  num_proposals) = post_processing.batch_multiclass_non_max_suppression(</span><br><span class="line">    tf.expand_dims(proposal_boxes, axis=<span class="number">2</span>),</span><br><span class="line">    tf.expand_dims(rpn_objectness_softmax_without_background,</span><br><span class="line">                  axis=<span class="number">2</span>),</span><br><span class="line">    self._first_stage_nms_score_threshold,</span><br><span class="line">    self._first_stage_nms_iou_threshold,</span><br><span class="line">    self._first_stage_max_proposals,</span><br><span class="line">    self._first_stage_max_proposals,</span><br><span class="line">    clip_window=clip_window)</span><br><span class="line">    ...</span><br><span class="line">  <span class="comment"># normalize proposal boxes</span></span><br><span class="line">  <span class="function"><span class="keyword">def</span> <span class="title">normalize_boxes</span><span class="params">(args)</span>:</span></span><br><span class="line">    ...</span><br><span class="line">  ...</span><br></pre></td></tr></table></figure></p>
<p>Now, we jump into postprocess function</p>
<p>postprocess: Convert prediction tensors to final detections. Input for this function is the output for predict function.<br><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">postprocess</span><span class="params">(self, prediction_dict, true_image_shapes)</span>:</span></span><br><span class="line">  <span class="comment"># FirstStage -&gt; _postprocess_rpn -&gt; explained before</span></span><br><span class="line">  <span class="comment"># SecondStage -&gt; _postprocess_box_classifier -&gt; explained below</span></span><br><span class="line">  <span class="comment"># ThirdStage -&gt; already postprocessed, just simple trainsfer</span></span><br><span class="line">  <span class="keyword">with</span> tf.name_scope(<span class="string">'FirstStagePostprocessor'</span>):</span><br><span class="line">    <span class="keyword">if</span> self._number_of_stages == <span class="number">1</span>:</span><br><span class="line">      proposal_boxes, proposal_scores, num_proposals = self._postprocess_rpn(</span><br><span class="line">        prediction_dict[<span class="string">'rpn_box_encodings'</span>],</span><br><span class="line">        prediction_dict[<span class="string">'rpn_objectness_predictions_with_background'</span>],</span><br><span class="line">        prediction_dict[<span class="string">'anchors'</span>],</span><br><span class="line">        true_image_shapes,</span><br><span class="line">        true_image_shapes)</span><br><span class="line">    <span class="keyword">return</span> &#123;</span><br><span class="line">      fields.DetectionResultFields.detection_boxes: proposal_boxes,</span><br><span class="line">      fields.DetectionResultFields.detection_scores: proposal_scores,</span><br><span class="line">      fields.DetectionResultFields.num_detections:</span><br><span class="line">          tf.to_float(num_proposals),</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">  <span class="comment"># TODO(jrru): Remove mask_predictions from _post_process_box_classifier.</span></span><br><span class="line">  <span class="keyword">with</span> tf.name_scope(<span class="string">'SecondStagePostprocessor'</span>):</span><br><span class="line">    <span class="keyword">if</span> (self._number_of_stages == <span class="number">2</span> <span class="keyword">or</span></span><br><span class="line">        (self._number_of_stages == <span class="number">3</span> <span class="keyword">and</span> self._is_training)):</span><br><span class="line">      mask_predictions = prediction_dict.get(box_predictor.MASK_PREDICTIONS)</span><br><span class="line">      detections_dict = self._postprocess_box_classifier(</span><br><span class="line">        prediction_dict[<span class="string">'refined_box_encodings'</span>],</span><br><span class="line">        prediction_dict[<span class="string">'class_predictions_with_background'</span>],</span><br><span class="line">        prediction_dict[<span class="string">'proposal_boxes'</span>],</span><br><span class="line">        prediction_dict[<span class="string">'num_proposals'</span>],</span><br><span class="line">        true_image_shapes,</span><br><span class="line">        mask_predictions=mask_predictions)</span><br><span class="line">  <span class="keyword">return</span> detections_dict</span><br><span class="line"></span><br><span class="line">  <span class="keyword">if</span> self._number_of_stages == <span class="number">3</span>:</span><br><span class="line">    <span class="comment"># Post processing is already performed in 3rd stage. We need to transfer</span></span><br><span class="line">    <span class="comment"># postprocessed tensors from `prediction_dict` to `detections_dict`.</span></span><br><span class="line">    detections_dict = &#123;&#125;</span><br><span class="line">    <span class="keyword">for</span> key <span class="keyword">in</span> prediction_dict:</span><br><span class="line">      <span class="keyword">if</span> key == fields.DetectionResultFields.detection_masks:</span><br><span class="line">        detections_dict[key] = tf.sigmoid(prediction_dict[key])</span><br><span class="line">      <span class="keyword">elif</span> <span class="string">'detection'</span> <span class="keyword">in</span> key:</span><br><span class="line">        detections_dict[key] = prediction_dict[key]</span><br><span class="line">    <span class="keyword">return</span> detections_dict</span><br></pre></td></tr></table></figure></p>
<p>_postprocess_box_classifier: Convert second stage box classifier to result. Similar to first stage operations.<br><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">_postprocess_box_classifier</span><span class="params">(self,</span></span></span><br><span class="line"><span class="function"><span class="params">                                refined_box_encodings,</span></span></span><br><span class="line"><span class="function"><span class="params">                                class_predictions_with_background,</span></span></span><br><span class="line"><span class="function"><span class="params">                                proposal_boxes,</span></span></span><br><span class="line"><span class="function"><span class="params">                                num_proposals,</span></span></span><br><span class="line"><span class="function"><span class="params">                                image_shapes,</span></span></span><br><span class="line"><span class="function"><span class="params">                                mask_predictions=None)</span>:</span></span><br><span class="line">  ...</span><br><span class="line">  <span class="comment"># _second_stage_nms_fn here is initialized at __init__</span></span><br><span class="line">  (nmsed_boxes, nmsed_scores, nmsed_classes, nmsed_masks, _,</span><br><span class="line">  num_detections) = self._second_stage_nms_fn(</span><br><span class="line">    refined_decoded_boxes_batch,</span><br><span class="line">    class_predictions_batch,</span><br><span class="line">    clip_window=clip_window,</span><br><span class="line">    change_coordinate_frame=<span class="keyword">True</span>,</span><br><span class="line">    num_valid_boxes=num_proposals,</span><br><span class="line">    masks=mask_predictions_batch)</span><br><span class="line">  ...</span><br></pre></td></tr></table></figure></p>
<p>Final part: Loss</p>
<p>loss: depends on stage number. First stage loss: self._loss_rpn, After first stage: self._loss_box_classifier<br><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">loss</span><span class="params">(self, prediction_dict, true_image_shapes, scope=None)</span>:</span></span><br><span class="line">  <span class="keyword">with</span> tf.name_scope(scope, <span class="string">'Loss'</span>, prediction_dict.values()):</span><br><span class="line">    (groundtruth_boxlists, groundtruth_classes_with_background_list,</span><br><span class="line">    groundtruth_masks_list, groundtruth_weights_list</span><br><span class="line">    ) = self._format_groundtruth_data(true_image_shapes)</span><br><span class="line">    loss_dict = self._loss_rpn(</span><br><span class="line">      prediction_dict[<span class="string">'rpn_box_encodings'</span>],</span><br><span class="line">      prediction_dict[<span class="string">'rpn_objectness_predictions_with_background'</span>],</span><br><span class="line">      prediction_dict[<span class="string">'anchors'</span>], groundtruth_boxlists,</span><br><span class="line">      groundtruth_classes_with_background_list, groundtruth_weights_list)</span><br><span class="line">    <span class="comment"># For stage 2 or 3</span></span><br><span class="line">    <span class="keyword">if</span> self._number_of_stages &gt; <span class="number">1</span>:</span><br><span class="line">      loss_dict.update(</span><br><span class="line">        self._loss_box_classifier(</span><br><span class="line">          prediction_dict[<span class="string">'refined_box_encodings'</span>],</span><br><span class="line">          prediction_dict[<span class="string">'class_predictions_with_background'</span>],</span><br><span class="line">          prediction_dict[<span class="string">'proposal_boxes'</span>],</span><br><span class="line">          prediction_dict[<span class="string">'num_proposals'</span>],</span><br><span class="line">          groundtruth_boxlists,</span><br><span class="line">          groundtruth_classes_with_background_list,</span><br><span class="line">          groundtruth_weights_list,</span><br><span class="line">          prediction_dict[<span class="string">'image_shape'</span>],</span><br><span class="line">          prediction_dict.get(<span class="string">'mask_predictions'</span>),</span><br><span class="line">          groundtruth_masks_list,</span><br><span class="line">      ))</span><br><span class="line">  <span class="keyword">return</span> loss_dict</span><br></pre></td></tr></table></figure></p>

          
        
      
    </div>
    
    
    

    

    

    

    <footer class="post-footer">
      

      

      

      
      
        <div class="post-eof"></div>
      
    </footer>
  </div>
  
  
  
  </article>


    
      

  

  
  
  

  <article class="post post-type-normal" itemscope itemtype="http://schema.org/Article">
  
  
  
  <div class="post-block">
    <link itemprop="mainEntityOfPage" href="http://chenghaz.github.io/2018/08/26/optimization-algorithms/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="name" content="chenghaz">
      <meta itemprop="description" content="">
      <meta itemprop="image" content="/uploads/avatar.png">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="chenghaz Official 1.0">
    </span>

    
      <header class="post-header">

        
        
          <h1 class="post-title" itemprop="name headline">
                
                <a class="post-title-link" href="/2018/08/26/optimization-algorithms/" itemprop="url">Optimization Algorithms - Deeplearning.ai</a></h1>
        

        <div class="post-meta">
          <span class="post-time">
            
              <span class="post-meta-item-icon">
                <i class="fa fa-calendar-o"></i>
              </span>
              
                <span class="post-meta-item-text">Posted on</span>
              
              <time title="Post created" itemprop="dateCreated datePublished" datetime="2018-08-26T11:03:13-07:00">
                2018-08-26
              </time>
            

            

            
          </span>

          

          
            
          

          
          

          

          

          

        </div>
      </header>
    

    
    
    
    <div class="post-body" itemprop="articleBody">

      
      

      
        
          
            <p><strong>Mini-batch gradient descent</strong><br>Split whole dataset into mini-batches<br>For batch gradient descent - go through the whole dataset and then update<br><img src="/2018/08/26/optimization-algorithms/1.png"></p>
<p><strong>Understanding mini-batch gradient descent</strong><br><img src="/2018/08/26/optimization-algorithms/2.png"><br>Choosing mini-batch size<br>if mini-batch size = m(dataset size) - Batch gradient descent - Too long per iteration<br>if mini-batch size = 1 - SGD every example is a mini-batch - lose speedup from vectorization</p>
<p>Guideline for select mini-batch size<br>If small training set: just use batch gradient descent<br>Typical mini-batch size: 64, 128, 256, 512<br>Make sure mini-batch fit in CPU/GPU size</p>
<p><strong>Exponentially weighted averages</strong><br><img src="/2018/08/26/optimization-algorithms/3.png"><br>(1 - \eps)^(1 / \eps) = 1 / e<br>Bias correction in exponential weighted averages:<br>At first, the v0 is initialized as 0, the problems occur. So we need to some coefficient to warmup our function.<br><img src="/2018/08/26/optimization-algorithms/4.png"></p>
<p><strong>Gradient descent with momentum</strong><br>Use a similar formula as Exponentially weighted averages.<br>Use momentum will take steps that have much smaller oscillations.<br>Momentum term: velocity, derivative: acceleration.<br><img src="/2018/08/26/optimization-algorithms/5.png"><br>In practice, people don’t use bias correction for this algorithm. </p>
<p><strong>RMSprop</strong><br>On iteration t,<br>    Compute d_W, d_b on corrent mini-batch<br>    S_dw = beta S_dw + (1 - beta) d_W^2 (element-wise)<br>    W = W - alpha (d_W / sqrt(S_dw))<br>    same for b<br>“起到的效果是在参数空间更为平缓的方向，会取得更大的进步（因为平缓，所以历史梯度平方和较小，对应学习下降的幅度较小），并且能够使得陡峭的方向变得平缓，从而加快训练速度。” -<a href="https://zhuanlan.zhihu.com/p/34230849" target="_blank" rel="noopener">https://zhuanlan.zhihu.com/p/34230849</a></p>
<p><strong>Adam optimization algorithm</strong><br>Momentum and RMSprop and bias correction<br><img src="/2018/08/26/optimization-algorithms/6.png"><br>Hyperparameters: alpha: needs to be tuned, beta1: 0.9, beta2: 0.999</p>
<p><strong>Learning rate Decay</strong><br>Take a smaller step when approaching to optimal solution<br>1 epoch -&gt; 1 pass through data<br>learning rate alpha = 1 / (1 + decay_rate <em> epoch_number)<br>exponential weight decay = alpha = 0.95^epoch_num </em> alpha_0</p>
<p><strong>The problem of local optima</strong><br>Since the model have multiple dimensions, it is hard to find a saddle point(zero gradient)<br>Plateaus: the gradient is close to zero. It will take a long time to get a optimal solution (make learning slow)</p>

          
        
      
    </div>
    
    
    

    

    

    

    <footer class="post-footer">
      

      

      

      
      
        <div class="post-eof"></div>
      
    </footer>
  </div>
  
  
  
  </article>


    
      

  

  
  
  

  <article class="post post-type-normal" itemscope itemtype="http://schema.org/Article">
  
  
  
  <div class="post-block">
    <link itemprop="mainEntityOfPage" href="http://chenghaz.github.io/2018/08/15/small-net/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="name" content="chenghaz">
      <meta itemprop="description" content="">
      <meta itemprop="image" content="/uploads/avatar.png">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="chenghaz Official 1.0">
    </span>

    
      <header class="post-header">

        
        
          <h1 class="post-title" itemprop="name headline">
                
                <a class="post-title-link" href="/2018/08/15/small-net/" itemprop="url">CNN model comparison - for some model that need much lower memory cost</a></h1>
        

        <div class="post-meta">
          <span class="post-time">
            
              <span class="post-meta-item-icon">
                <i class="fa fa-calendar-o"></i>
              </span>
              
                <span class="post-meta-item-text">Posted on</span>
              
              <time title="Post created" itemprop="dateCreated datePublished" datetime="2018-08-15T14:59:15-07:00">
                2018-08-15
              </time>
            

            

            
          </span>

          

          
            
          

          
          

          

          

          

        </div>
      </header>
    

    
    
    
    <div class="post-body" itemprop="articleBody">

      
      

      
        
          
            <img src="/2018/08/15/small-net/1.png">
<p><a href="https://medium.com/@yu4u/why-mobilenet-and-its-variants-e-g-shufflenet-are-fast-1c7048b9618d" target="_blank" rel="noopener">https://medium.com/@yu4u/why-mobilenet-and-its-variants-e-g-shufflenet-are-fast-1c7048b9618d</a>  </p>

          
        
      
    </div>
    
    
    

    

    

    

    <footer class="post-footer">
      

      

      

      
      
        <div class="post-eof"></div>
      
    </footer>
  </div>
  
  
  
  </article>


    
      

  

  
  
  

  <article class="post post-type-normal" itemscope itemtype="http://schema.org/Article">
  
  
  
  <div class="post-block">
    <link itemprop="mainEntityOfPage" href="http://chenghaz.github.io/2018/08/06/FCN/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="name" content="chenghaz">
      <meta itemprop="description" content="">
      <meta itemprop="image" content="/uploads/avatar.png">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="chenghaz Official 1.0">
    </span>

    
      <header class="post-header">

        
        
          <h1 class="post-title" itemprop="name headline">
                
                <a class="post-title-link" href="/2018/08/06/FCN/" itemprop="url">Fully Convolutional Network</a></h1>
        

        <div class="post-meta">
          <span class="post-time">
            
              <span class="post-meta-item-icon">
                <i class="fa fa-calendar-o"></i>
              </span>
              
                <span class="post-meta-item-text">Posted on</span>
              
              <time title="Post created" itemprop="dateCreated datePublished" datetime="2018-08-06T11:43:46-07:00">
                2018-08-06
              </time>
            

            

            
          </span>

          

          
            
          

          
          

          

          

          

        </div>
      </header>
    

    
    
    
    <div class="post-body" itemprop="articleBody">

      
      

      
        
          
            <img src="/2018/08/06/FCN/1.png">
<p>The final output layer will be the same height and width as the input image, but the number of channels will be equal to the number of classes. If we’re classifying each pixel as one of fifteen different classes, then the final output layer will be height x width x 15 classes.  </p>

          
        
      
    </div>
    
    
    

    

    

    

    <footer class="post-footer">
      

      

      

      
      
        <div class="post-eof"></div>
      
    </footer>
  </div>
  
  
  
  </article>


    
      

  

  
  
  

  <article class="post post-type-normal" itemscope itemtype="http://schema.org/Article">
  
  
  
  <div class="post-block">
    <link itemprop="mainEntityOfPage" href="http://chenghaz.github.io/2018/08/06/YOLO-detection/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="name" content="chenghaz">
      <meta itemprop="description" content="">
      <meta itemprop="image" content="/uploads/avatar.png">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="chenghaz Official 1.0">
    </span>

    
      <header class="post-header">

        
        
          <h1 class="post-title" itemprop="name headline">
                
                <a class="post-title-link" href="/2018/08/06/YOLO-detection/" itemprop="url">YOLO object detection note</a></h1>
        

        <div class="post-meta">
          <span class="post-time">
            
              <span class="post-meta-item-icon">
                <i class="fa fa-calendar-o"></i>
              </span>
              
                <span class="post-meta-item-text">Posted on</span>
              
              <time title="Post created" itemprop="dateCreated datePublished" datetime="2018-08-06T10:28:37-07:00">
                2018-08-06
              </time>
            

            

            
          </span>

          

          
            
          

          
          

          

          

          

        </div>
      </header>
    

    
    
    
    <div class="post-body" itemprop="articleBody">

      
      

      
        
          
            <p><strong>Classification with localization</strong><br>Have output 4 more outputs -&gt; bounding box<br>Depends on whether contains an object.  </p>
<p><strong>Landmark detection</strong><br>Find some landmark of the face -&gt; is that a face and coordinate of face<br>Add a brunch of outputs  </p>
<p><strong>Object detection(sliding window)</strong><br>Choose a sliding window through the picture -&gt; predict that region<br>The choose different size of sliding window<br>Much more expensive and slow  </p>
<p><strong>Convolutional implementation of sliding window</strong><br>Turning FC layer into Conv layer<br><img src="/2018/08/06/YOLO-detection/1.png"><br>Position of bounding box maybe inaccurate.</p>
<p><strong>Bounding box predictions</strong><br>YOLO split into grids. For each grid cell, have a prediction output<br><img src="/2018/08/06/YOLO-detection/2.png"></p>
<ol>
<li>Like image classification and localization  </li>
<li>Convolutional implementation (fast, real-time) </li>
</ol>
<p><strong>Intersection Over Union(IoU)</strong><br>Compute union over bounding boxes (size of intersection / size of union)<br>Correct if IoU &gt;= 0.5 (hyper-parameter)<br>Measure of the overlap between two bounding boxes  </p>
<p><strong>Non-max suppression (NMS)</strong><br>Clean up the multiple detections<br>Suppress the higher IoU bounding boxes<br>Output the maximum probability box<br>First step, discard all boxes that have a lower probability<br>While loop(any remaining boxes), pick the box with highest probability, then output the prediction Finally, Discard higher IoU boxes.  </p>
<p><strong>Anchor boxes</strong><br>Predefine several size of anchor boxes<br><img src="/2018/08/06/YOLO-detection/3.png"><br>With two anchor boxes, each object in training image is assigned to grid cell that contains object’s midpoint and anchor box for the grid cell with highest IoU.<br><img src="/2018/08/06/YOLO-detection/4.png"><br>If objects are more than anchor boxes number, this algorithm cannot handle.<br>Or several object share save anchor box shape.  </p>
<p><strong>YOLO algorithm – put together</strong> </p>

          
        
      
    </div>
    
    
    

    

    

    

    <footer class="post-footer">
      

      

      

      
      
        <div class="post-eof"></div>
      
    </footer>
  </div>
  
  
  
  </article>


    
      

  

  
  
  

  <article class="post post-type-normal" itemscope itemtype="http://schema.org/Article">
  
  
  
  <div class="post-block">
    <link itemprop="mainEntityOfPage" href="http://chenghaz.github.io/2018/06/18/language-id/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="name" content="chenghaz">
      <meta itemprop="description" content="">
      <meta itemprop="image" content="/uploads/avatar.png">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="chenghaz Official 1.0">
    </span>

    
      <header class="post-header">

        
        
          <h1 class="post-title" itemprop="name headline">
                
                <a class="post-title-link" href="/2018/06/18/language-id/" itemprop="url">Several RNN-LSTM based speech recognition paper</a></h1>
        

        <div class="post-meta">
          <span class="post-time">
            
              <span class="post-meta-item-icon">
                <i class="fa fa-calendar-o"></i>
              </span>
              
                <span class="post-meta-item-text">Posted on</span>
              
              <time title="Post created" itemprop="dateCreated datePublished" datetime="2018-06-18T10:28:53-07:00">
                2018-06-18
              </time>
            

            

            
          </span>

          

          
            
          

          
          

          

          

          

        </div>
      </header>
    

    
    
    
    <div class="post-body" itemprop="articleBody">

      
      

      
        
          
            <p><strong>1. Automatic Language Identification using Long Short-Term Memory Recurrent Neural Networks</strong><br><em>2014 IEEE International Conference on Acoustics, Speech and Signal Processing (ICASSP)</em></p>
<ol>
<li>i-vector based LID system<br>39 dimensional PLP coefficients, 21 frames (+-10 left-right context) size: 38 * 21 input<br>hidden units: 2560 - 2560 - Softmax<br>used asynchronous stochastic gradient descent within the DistBelief framework<br>learning rate: 1e-03, minibatch size: 200</li>
<li>LSTM-RNN architecture<img src="/2018/06/18/language-id/LSTM.png" title="LSTM unit">
the LSTM-RNN architecture contains 512 memory cells<br>used asynchronous stochastic gradient descent (ASGD) and the truncated back-propagation through time (BPTT) learning algorithm within a distributed training framework </li>
</ol>
<p><strong>2. End-to-End Text-Dependent Speaker Verification</strong><br><em>2016 IEEE International Conference on Acoustics, Speech and Signal Processing (ICASSP)</em><br>Speaker verification is the process of verifying, based on a speaker’s known utterances, whether an utterance belongs to the speaker<br>Speaker Verification Protocal: 1. Training 2. Enrollment 3. Evaluation<br>D-vectors are derived from a deep neural network (DNN), as speaker representation of an utterance<br><img src="/2018/06/18/language-id/DNN.png" title="Deep neural network (DNN) for D-vectors"><br>End-to-End architecture:<br><img src="/2018/06/18/language-id/LSTM-SV.png"></p>

          
        
      
    </div>
    
    
    

    

    

    

    <footer class="post-footer">
      

      

      

      
      
        <div class="post-eof"></div>
      
    </footer>
  </div>
  
  
  
  </article>


    
      

  

  
  
  

  <article class="post post-type-normal" itemscope itemtype="http://schema.org/Article">
  
  
  
  <div class="post-block">
    <link itemprop="mainEntityOfPage" href="http://chenghaz.github.io/2018/06/09/First-Post/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="name" content="chenghaz">
      <meta itemprop="description" content="">
      <meta itemprop="image" content="/uploads/avatar.png">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="chenghaz Official 1.0">
    </span>

    
      <header class="post-header">

        
        
          <h1 class="post-title" itemprop="name headline">
                
                <a class="post-title-link" href="/2018/06/09/First-Post/" itemprop="url">未来简史</a></h1>
        

        <div class="post-meta">
          <span class="post-time">
            
              <span class="post-meta-item-icon">
                <i class="fa fa-calendar-o"></i>
              </span>
              
                <span class="post-meta-item-text">Posted on</span>
              
              <time title="Post created" itemprop="dateCreated datePublished" datetime="2018-06-09T11:38:13-07:00">
                2018-06-09
              </time>
            

            

            
          </span>

          

          
            
          

          
          

          

          

          

        </div>
      </header>
    

    
    
    
    <div class="post-body" itemprop="articleBody">

      
      

      
        
          
            <p>饥荒、疾病、战争（“丛林法则”、“契诃夫法则”）是主要造成大规模人类死去的原因（古代and近代）<br>21世纪会有哪些议题取代饥荒、瘟疫和战争呢？ 1.长生不老 2.幸福快乐（生理、生物）<br>科学的用途：1. 预测未来 2. 拓宽视野。 同时，研究历史是为了挣脱过去的桎梏</p>
<p>第一部分 - 智人征服世界<br>智能设计取代自然选择、将生命形式从有机领域延伸到无机领域<br>农业革命（第一次革命）既是经济上的革命，也成了宗教上的革命：通过宗教来赋予“人”特殊的意义<br>现代科学和工业的兴起（第二次革命）中，变成的人类的独角戏<br>农业革命促成了有神论宗教，科技革命催生了人文主义宗教<br>现有的法律、政治和经济制度而言，相信人类有永恒的灵魂而动物只有短暂的肉体（人为什么会与众不同），是制度的重要支柱<br>“他心问题” - （我们生活在的环境是一个虚拟环境）- 图灵测试<br>“智人”能够统治世界，是因为只有智人能够大规模灵活合作<br>历史的展开方式：人类编织出一张意义的网，并全然相信它</p>
<p>第二部分 - 智人为世界赋予意义<br>文字和货币让人突破了人类大脑的数据处理的限制，建造出幅员辽阔的王国<br>人类合作网络的力量就是依赖于真实与虚构之间的微妙平衡</p>

          
        
      
    </div>
    
    
    

    

    

    

    <footer class="post-footer">
      

      

      

      
      
        <div class="post-eof"></div>
      
    </footer>
  </div>
  
  
  
  </article>


    
  </section>

  


          </div>
          


          

        </div>
        
          
  
  <div class="sidebar-toggle">
    <div class="sidebar-toggle-line-wrap">
      <span class="sidebar-toggle-line sidebar-toggle-line-first"></span>
      <span class="sidebar-toggle-line sidebar-toggle-line-middle"></span>
      <span class="sidebar-toggle-line sidebar-toggle-line-last"></span>
    </div>
  </div>

  <aside id="sidebar" class="sidebar">
    
    <div class="sidebar-inner">

      

      

      <section class="site-overview-wrap sidebar-panel sidebar-panel-active">
        <div class="site-overview">
          <div class="site-author motion-element" itemprop="author" itemscope itemtype="http://schema.org/Person">
            
              <img class="site-author-image" itemprop="image"
                src="/uploads/avatar.png"
                alt="chenghaz" />
            
              <p class="site-author-name" itemprop="name">chenghaz</p>
              <p class="site-description motion-element" itemprop="description">Why always me - Mario Balotelli</p>
          </div>

          <nav class="site-state motion-element">

            
              <div class="site-state-item site-state-posts">
              
                <a href="/archives/">
              
                  <span class="site-state-item-count">10</span>
                  <span class="site-state-item-name">posts</span>
                </a>
              </div>
            

            

            
              
              
              <div class="site-state-item site-state-tags">
                
                  <span class="site-state-item-count">9</span>
                  <span class="site-state-item-name">tags</span>
                
              </div>
            

          </nav>

          

          

          
          

          
          

          

        </div>
      </section>

      

      

    </div>
  </aside>


        
      </div>
    </main>

    <footer id="footer" class="footer">
      <div class="footer-inner">
        <div class="copyright">&copy; <span itemprop="copyrightYear">2018</span>
  <span class="with-love">
    <i class="fa fa-user"></i>
  </span>
  <span class="author" itemprop="copyrightHolder">chenghaz</span>

  
</div>


  <div class="powered-by">Powered by <a class="theme-link" target="_blank" href="https://hexo.io">Hexo</a></div>



  <span class="post-meta-divider">|</span>



  <div class="theme-info">Theme &mdash; <a class="theme-link" target="_blank" href="https://github.com/iissnan/hexo-theme-next">NexT.Gemini</a> v5.1.4</div>




        







        
      </div>
    </footer>

    
      <div class="back-to-top">
        <i class="fa fa-arrow-up"></i>
        
      </div>
    

    

  </div>

  

<script type="text/javascript">
  if (Object.prototype.toString.call(window.Promise) !== '[object Function]') {
    window.Promise = null;
  }
</script>









  












  
  
    <script type="text/javascript" src="/lib/jquery/index.js?v=2.1.3"></script>
  

  
  
    <script type="text/javascript" src="/lib/fastclick/lib/fastclick.min.js?v=1.0.6"></script>
  

  
  
    <script type="text/javascript" src="/lib/jquery_lazyload/jquery.lazyload.js?v=1.9.7"></script>
  

  
  
    <script type="text/javascript" src="/lib/velocity/velocity.min.js?v=1.2.1"></script>
  

  
  
    <script type="text/javascript" src="/lib/velocity/velocity.ui.min.js?v=1.2.1"></script>
  

  
  
    <script type="text/javascript" src="/lib/fancybox/source/jquery.fancybox.pack.js?v=2.1.5"></script>
  


  


  <script type="text/javascript" src="/js/src/utils.js?v=5.1.4"></script>

  <script type="text/javascript" src="/js/src/motion.js?v=5.1.4"></script>



  
  


  <script type="text/javascript" src="/js/src/affix.js?v=5.1.4"></script>

  <script type="text/javascript" src="/js/src/schemes/pisces.js?v=5.1.4"></script>



  

  


  <script type="text/javascript" src="/js/src/bootstrap.js?v=5.1.4"></script>



  


  




	





  





  












  





  

  

  

  
  

  

  

  

</body>
</html>
